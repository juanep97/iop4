name: CI


# by not building all branches on push, we avoid the duplicated builds in PRs
on:
  push:
    branches:
      - main
    tags:
      - '**'
  pull_request:

concurrency:
  # cancel previous runs of the same workflow for the same PR when new commits are pushed
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  NUMBA_NUM_THREADS: 1
  MPLBACKEND: Agg
  PYTEST_ADDOPTS: --color=yes


jobs:

  static-code-checks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

  tests:
    runs-on: [self-hosted, x64, Linux, ubuntu, generic]
    strategy:
      max-parallel: 1
      matrix:
        python-version: ["3.11"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Update pip
        run: |
          python -m pip install --upgrade pip

      - name: Build the package
        run: |
          pip install build
          python -m build

      - name: Install the package
        run: pip install .[test]

      - name: Install the package in editable mode with all additional dependencies
        run: pip install --editable .[all]

      - name: Extract test data version from source code
        env:
          TEST_DATA_PASSWORD: ${{ secrets.test_data_password }}
        run: |
          export TESTDATA_MD5SUM=`grep 'TESTDATA_MD5SUM' ./tests/conftest.py | awk -F"'" '{print $2}' | tr -d '\n'`
          echo "TESTDATA_MD5SUM=$TESTDATA_MD5SUM" >> $GITHUB_ENV

      - name: Use mounted astrometry index files and test dataset
        run: |
          ln -s /mnt/astrometry_cache $HOME/.astrometry_cache
          ln -s /mnt/test_datasets/iop4testdata.$TESTDATA_MD5SUM.tar.gz $HOME/iop4testdata.$TESTDATA_MD5SUM.tar.gz 
      
      - name: Check that index files and test dataset were correctly mounted
        run: |
          ls -lh $HOME/.astrometry_cache/5200/index-5200-00.fits
          ls -lh $HOME/iop4testdata.$TESTDATA_MD5SUM.tar.gz
      
      - name: Run tests with coverage report (with -o log_cli=true -o log_cli_level=DEBUG to debug CI actions)
        run: pytest -o log_cli=true -o log_cli_level=DEBUG -vxs --cov=iop4lib tests
      
      - name: Upload coverage data
        uses: actions/upload-artifact@v4
        with:
          name: coverage-data-${{ matrix.python-version }}
          path: .coverage.*
          if-no-files-found: ignore

# From Hynek Schlawack (https://hynek.me/articles/ditch-codecov-python/)
  coverage:
    name: Combine & check coverage
    needs: tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: python -Im pip install --upgrade coverage[toml]
      - uses: actions/download-artifact@v4
        with:
          pattern: coverage-data-*
          merge-multiple: true

      - name: Combine coverage & fail if it's <100%.
        run: |
          python -Im coverage combine
          python -Im coverage html --skip-covered --skip-empty

          # Report and write to summary.
          python -Im coverage report --format=markdown >> $GITHUB_STEP_SUMMARY

          # Report again and fail if under 100%.
          python -Im coverage report --fail-under=100

      - name: Upload HTML report if check failed.
        uses: actions/upload-artifact@v4
        with:
          name: html-report
          path: htmlcov
        if: ${{ failure() }}


  docs:
    runs-on: [self-hosted, x64, Linux, ubuntu, generic]
    # Don't run if this is a tag push, already done during docs deployment (docs.yml)
    if:  ${{ !startsWith(github.ref, 'refs/tags/v') }}
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Update pip
        run: |
          python -m pip install --upgrade pip

      - name: Install required packages
        run: |
          sudo apt-get -y install pandoc make

      - name: Install doc dependencies
        run: |
          pip install -e .[doc]
          python -c 'import iop4lib; print(iop4lib.__version__)'

      - name: Extract test data version from source code
        env:
          TEST_DATA_PASSWORD: ${{ secrets.test_data_password }}
        run: |
          export TESTDATA_MD5SUM=`grep 'TESTDATA_MD5SUM' ./tests/conftest.py | awk -F"'" '{print $2}' | tr -d '\n'`
          echo "TESTDATA_MD5SUM=$TESTDATA_MD5SUM" >> $GITHUB_ENV

      - name: Use mounted astrometry index files and test dataset
        run: |
          ln -s /mnt/astrometry_cache $HOME/.astrometry_cache
          ln -s /mnt/test_datasets/iop4testdata.$TESTDATA_MD5SUM.tar.gz $HOME/iop4testdata.$TESTDATA_MD5SUM.tar.gz 
      
      - name: Check that index files and test dataset were correctly mounted
        run: |
          ls -lh $HOME/.astrometry_cache/5200/index-5200-00.fits
          ls -lh $HOME/iop4testdata.$TESTDATA_MD5SUM.tar.gz

      - name: Extract test data in the default data folder
        run: |
          tar -xzf $HOME/iop4testdata.$TESTDATA_MD5SUM.tar.gz -C $HOME
          mv $HOME/iop4testdata $HOME/.iop4data

      - name: Create the DB
        run: |
          python iop4site/manage.py makemigrations
          python iop4site/manage.py makemigrations iop4api
          python iop4site/manage.py migrate --no-input
          python iop4site/manage.py loaddata $HOME/.iop4data/testcatalog.yaml
          ls -lh $HOME/.iop4data/

      - name: Run iop4 on the test data
        run: iop4 --list-local
  
      - name: Build docs
        run: make docs-sphinx